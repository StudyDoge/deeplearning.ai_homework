{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
    "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
    "\n",
    "init = tf.global_variables_initializer()         # When init is run later (session.run(init)),\n",
    "                                                 # the loss variable will be initialized and ready to be computed\n",
    "with tf.Session() as session:                    # Create a session and print the output\n",
    "    session.run(init)                            # Initializes the variables\n",
    "    print(session.run(loss))                     # Prints the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n",
      "20\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)\n",
    "sess = tf.Session()\n",
    "print(sess.run(c))\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function: \n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns: \n",
    "    result -- runs the session for Y = WX + b \n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    ### START CODE HERE ### (4 lines of code)\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4,1), name  = \"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "     # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    # close the session \n",
    "    sess.close()\n",
    "\n",
    "    return result\n",
    "\n",
    "print(linear_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.9999938\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "\n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### ( approx. 4 lines of code)\n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name = \"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. Please use the method 2 explained above. \n",
    "    # You should use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as sess:\n",
    "        # Run session and call the output \"result\"\n",
    "        result = sess.run(sigmoid, feed_dict = {x:z})\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result\n",
    "\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [0.6931472 0.6931472 0.645074  0.6023122]\n"
     ]
    }
   ],
   "source": [
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "\n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0) \n",
    "\n",
    "    Note: What we've been calling \"z\" and \"y\" in this class are respectively called \"logits\" and \"labels\" \n",
    "    in the TensorFlow documentation. So logits will feed into z, and labels into y. \n",
    "\n",
    "    Returns:\n",
    "    cost -- runs the session of the cost (formula (2))\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "\n",
    "    # Create the placeholders for \"logits\" (z) and \"labels\" (y) (approx. 2 lines)\n",
    "    z = tf.placeholder(tf.float32, name='z')\n",
    "    y = tf.placeholder(tf.float32, name='y')\n",
    "    \n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=z)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        cost = sess.run(cost, feed_dict={z:logits, y:labels})\n",
    "        \n",
    "    return cost\n",
    "\n",
    "\n",
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = \n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: one_hot_matrix\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "\n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "\n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    C = tf.constant(value=C, name='C')\n",
    "    ohm = tf.one_hot(labels, depth=C, axis=0)\n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(ohm)\n",
    "        \n",
    "    return one_hot\n",
    "        \n",
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \\n\" + str(one_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (12288, 1080)\n",
      "Y_train shape: (6, 1080)\n",
      "X_test shape: (12288, 120)\n",
      "Y_test shape: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Flatten the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "\n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None])\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "\n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\",[6,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-4a201a2ad5d4>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.855702\n",
      "Cost after epoch 100: 1.016458\n",
      "Cost after epoch 200: 0.733102\n",
      "Cost after epoch 300: 0.572938\n",
      "Cost after epoch 400: 0.468799\n",
      "Cost after epoch 500: 0.380979\n",
      "Cost after epoch 600: 0.313819\n",
      "Cost after epoch 700: 0.254258\n",
      "Cost after epoch 800: 0.203795\n",
      "Cost after epoch 900: 0.166410\n",
      "Cost after epoch 1000: 0.141497\n",
      "Cost after epoch 1100: 0.107579\n",
      "Cost after epoch 1200: 0.086229\n",
      "Cost after epoch 1300: 0.059415\n",
      "Cost after epoch 1400: 0.052237\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOW5wPHfk8m+J2RhCSEBwqYCYgTcUVxbrXWpitq6XtRq7bXtbe21rb3a3traRe1y3UVrXeqO+46oCBKQfScECGs2EkL25Ll/nBMcY0ImkMmZJM/385nPzLxne94MzDPnfc95X1FVjDHGmM6EeR2AMcaY3sEShjHGmIBYwjDGGBMQSxjGGGMCYgnDGGNMQCxhGGOMCYglDNPnicibInKF13EY09tZwjBBIyJFInKq13Go6lmq+rjXcQCIyBwRubYHjhMlIo+KSJWI7BSRH3Wy/i3uepXudlF+y3JE5EMRqRGRNW0/0062vVNElotIk4j8utsranqUJQzTq4lIuNcxtAqlWIBfA3nAMOBk4KcicmZ7K4rIGcCtwHQgBxgO/I/fKk8DXwADgNuA50UkPcBtNwA/BV7vlloZT1nCMJ4QkbNFZImI7BGReSIy3m/ZrSKyUUT2isgqETnPb9mVIvKpiPxFRMqBX7tln4jIH0WkQkQ2ichZftvs/1UfwLq5IjLXPfZ7IvJ3EXmygzpME5FiEfmZiOwEHhORFBF5TURK3P2/JiJZ7vq/BU4A/iYi1SLyN7d8jIi8KyLlIrJWRC7qhj/x94A7VbVCVVcDDwFXdrDuFcAjqrpSVSuAO1vXFZFRwCTgdlWtVdUXgOXABZ1tC6Cqj6vqm8DebqiT8ZglDNPjRGQS8ChwHc6v1geA2X5NGRtxvliTcH6tPikig/x2MQUoBDKA3/qVrQXSgD8Aj4iIdBDCgdZ9CvjcjevXwHc7qc5AIBXnl/xMnP9Tj7nvs4Fa4G8Aqnob8DFwk6rGq+pNIhIHvOseNwOYAfxDRA5r72Ai8g83ybb3WOaukwIMBpb6bboUaHefbnnbdTNFZIC7rFBV97ZZflgA25o+xhKG8cJ/AA+o6gJVbXb7F+qBqQCq+pyqblfVFlV9FlgPTPbbfruq/lVVm1S11i3brKoPqWoz8DgwCMjs4Pjtrisi2cDRwK9UtUFVPwFmd1KXFpxf3/XuL/AyVX1BVWvcL9nfAicdYPuzgSJVfcytz2LgBeDC9lZW1e+ranIHj9aztHj3udJv00ogoYMY4ttZF3f9tsva7utA25o+xhKG8cIw4Mf+v46BoTi/ihGR7/k1V+0BDsc5G2i1tZ197mx9oao17sv4dtY70LqDgXK/so6O5a9EVeta34hIrIg8ICKbRaQKmAski4ivg+2HAVPa/C0uwzlzOVjV7nOiX1kiHTcLVbezLu76bZe13deBtjV9jCUM44WtwG/b/DqOVdWnRWQYTnv7TcAAVU0GVgD+zUvBGmJ5B5AqIrF+ZUM72aZtLD8GRgNTVDURONEtlw7W3wp81OZvEa+qN7R3MBG53+3/aO+xEsDtS9gBTPDbdAKwsoM6rGxn3V2qWuYuGy4iCW2WrwxgW9PHWMIwwRYhItF+j3CchHC9iEwRR5yIfNP9UorD+VItARCRq3DOMIJOVTcDBTgd6ZEicgxwThd3k4DTb7FHRFKB29ss34VzJVGr14BRIvJdEYlwH0eLyNgOYrzeTSjtPfz7KJ4AfuF2wo/BaQac1UHMTwDXiMg4t//jF63rquo6YAlwu/v5nQeMx2k2O+C2AG59onG+a8LdfXR0tmVCnCUME2xv4HyBtj5+raoFOF9gfwMqcC69vBJAVVcBfwI+w/lyPQL4tAfjvQw4BigDfgM8i9O/Eqh7gBigFJgPvNVm+b3Ahe4VVPe5/RynA5cA23Gay34PRHFobse5eGAz8BFwt6q+BSAi2e4ZSTaAW/4H4EN3/c18NdFdAuTjfFZ3AReqakmA2z6E87nPwLkkt5bOLyQwIUpsAiVjOiYizwJrVLXtmYIx/Y6dYRjjx20OGiEiYeLc6HYu8LLXcRkTCkLpzlRjQsFA4EWc+zCKgRtU9QtvQzImNFiTlDHGmIBYk5QxxpiA9KkmqbS0NM3JyfE6DGOM6TUWLVpUqqrpgazbpxJGTk4OBQUFXodhjDG9hohsDnRda5IyxhgTEEsYxhhjAmIJwxhjTEAsYRhjjAmIJQxjjDEBsYRhjDEmIJYwjDHGBKTfJ4y6xmYemlvIvA2lXodijDEhrd8njPAw4cGPC3n0001eh2KMMSHNEoYvjAsmZfHh2hJ2763rfANjjOmn+n3CAPhOfhbNLcpLi7d5HYoxxoQsSxjAiPR4Jg5NZvbS7V6HYowxIcsShuvs8YNYub2KTaX7vA7FGGNCkiUM1zfHDwLg9WV2lmGMMe2xhOEalBTDEUOSmLveLq81xpj2WMLwc+yIAXyxpYLahmavQzHGmJBjCcPPMSMG0NisFGwu9zoUY4wJOUFLGCLyqIjsFpEVHSz/LxFZ4j5WiEiziKS6y4pEZLm7rMem0Ds6J5XwMGHexrKeOqQxxvQawTzDmAWc2dFCVb1bVSeq6kTg58BHqur/0/5kd3l+EGP8iriocCYNS2HO2pKeOqQxxvQaQUsYqjoXCLRtZwbwdLBi6YpTxmSwekcVOyprvQ7FGGNCiud9GCISi3Mm8oJfsQLviMgiEZnZyfYzRaRARApKSg79zOCUMRkAfLjGzjKMMcaf5wkDOAf4tE1z1HGqOgk4C7hRRE7saGNVfVBV81U1Pz09/ZCDycuIZ0hyDB+vt4RhjDH+QiFhXEKb5ihV3e4+7wZeAib3VDAiwpThqXy+qRxV7anDGmNMyPM0YYhIEnAS8IpfWZyIJLS+Bk4H2r3SKlim5KZStq+BjSXVPXlYY4wJaeHB2rGIPA1MA9JEpBi4HYgAUNX73dXOA95RVf8BnDKBl0SkNb6nVPWtYMXZnim5AwCYX1jOyIyEnjy0McaErKAlDFWdEcA6s3Auv/UvKwQmBCeqwAwbEEtGQhSfbyrn8qnDvAzFGGNCRij0YYQcpx9jgPVjGGOMH0sYHZicm8rOqjq2lNd4HYoxxoQESxgdmJqbCsCCTTaulDHGgCWMDo3MiCc1LpIFhZYwjDEGLGF0SEQ4OieFz4tsIEJjjAFLGAc0JXcAW8tr2b7HxpUyxhhLGAcw2e3H+Nz6MYwxxhLGgYwdlEhCdLh1fBtjDJYwDsgXJozPSmLFtkqvQzHGGM9ZwujE2IGJrNu1l6bmFq9DMcYYT1nC6MTYQYnUN7VQVLav85WNMaYPs4TRibGDEgFYtWOvx5EYY4y3LGF0YkRGHOFhwpodVV6HYowxnrKE0YmocB95mQksK7aOb2NM/2YJIwBTh6eysKicusZmr0MxxhjPWMIIwAl5adQ3tbBoc4XXoRhjjGcsYQRgcu4AwsOETzaUeh2KMcZ4xhJGAOKjwpk4NJl5G20gQmNM/xW0hCEij4rIbhFZ0cHyaSJSKSJL3Mev/JadKSJrRWSDiNwarBi74ujcVFZuq6S2wfoxjDH9UzDPMGYBZ3ayzseqOtF93AEgIj7g78BZwDhghoiMC2KcAckflkJTi7K0eI/XoRhjjCeCljBUdS5wMKP2TQY2qGqhqjYAzwDndmtwB+GoYSkA1vFtjOm3vO7DOEZElorImyJymFs2BNjqt06xW9YuEZkpIgUiUlBSUhK0QJNjIxmVGc/8QuvHMMb0T14mjMXAMFWdAPwVeNktl3bW1Y52oqoPqmq+quanp6cHIcwvTRudwfzCMqrqGoN6HGOMCUWeJQxVrVLVavf1G0CEiKThnFEM9Vs1C9juQYhfc8ZhmTQ2K3PWBu9MxhhjQpVnCUNEBoqIuK8nu7GUAQuBPBHJFZFI4BJgtldx+ps4NIW0+CjeWbnT61CMMabHhQdrxyLyNDANSBORYuB2IAJAVe8HLgRuEJEmoBa4RFUVaBKRm4C3AR/wqKquDFacXeELE44bOcCmbDXG9EtBSxiqOqOT5X8D/tbBsjeAN4IR16GakJXMK0u2s6uqjszEaK/DMcaYHuP1VVK9zsTsZACWbLX7MYwx/YsljC4aNyiRCJ9YwjDG9DuWMLooOsLH2EGJLNliCcMY079YwjgIE7KSWb6tkuaWDm8PMcaYPscSxkGYODSZ6vomNpZUex2KMcb0GEsYB2HCUOv4Nsb0P5YwDsLwtDgSosMtYRhj+hVLGAchLEw4YkgSK7dVeh2KMcb0GEsYB2nYgDiKK2q9DsMYY3qMJYyDlJUSQ9m+BmoamrwOxRhjeoQljIOUlRIDwDY7yzDG9BOWMA5SVkosgDVLGWP6DUsYB2moe4ZRXFHjcSTGGNMzLGEcpLT4KCLDw+wMwxjTb1jCOEhhYUJWcowlDGNMv2EJ4xAMSYlhS7k1SRlj+gdLGIcgNy2OTaX7cCYKNMaYvs0SxiEYnhZHdX0TJXvrvQ7FGGOCLmgJQ0QeFZHdIrKig+WXicgy9zFPRCb4LSsSkeUiskRECoIV46Eanh4PwMaSfR5HYowxwRfMM4xZwJkHWL4JOElVxwN3Ag+2WX6yqk5U1fwgxXfIhqfHAVBYasOcG2P6vvBg7VhV54pIzgGWz/N7Ox/IClYswTI4KYao8DA22RmGMaYfCJU+jGuAN/3eK/COiCwSkZkH2lBEZopIgYgUlJSUBDXItsLChNy0OApLLWEYY/q+oJ1hBEpETsZJGMf7FR+nqttFJAN4V0TWqOrc9rZX1Qdxm7Py8/N7/HKl4elxrNpe1dOHNcaYHufpGYaIjAceBs5V1bLWclXd7j7vBl4CJnsTYeeGp8WztaKWhqYWr0Mxxpig8ixhiEg28CLwXVVd51ceJyIJra+B04F2r7QKBcPT42huUbaUW7OUMaZvC1qTlIg8DUwD0kSkGLgdiABQ1fuBXwEDgH+ICECTe0VUJvCSWxYOPKWqbwUrzkPlf2ntyIwEj6MxxpjgCeZVUjM6WX4tcG075YXAhK9vEZr2X1prV0oZY/q4ULlKqtdKjI4gLT6KwhK7F8MY07dZwugGw9Pt0lpjTN9nCaMbjM5MYM2OKlpabBBCY0zfZQmjG4zPSmJfQ7OdZRhj+jRLGN1gfFYyAMuK93gciTHGBI8ljG4wMiOe2Egfy4orvQ7FGGOCxhJGN/CFCYcPTrIzDGNMn2YJo5scmZ3Mim1V1DU2ex2KMcYEhSWMbjJleCoNzS0s3lLhdSjGGBMUljC6SX5OKmEC8wvLvQ7FGGOCwhJGN0mMjuCwwUksKCzrfGVjjOmFLGF0oym5qXyxdY/1Yxhj+iRLGN1oyvABNDS1sHSrXS1ljOl7LGF0o8k5qYj1Yxhj+ihLGN0oKTaCMQMTWbDJ+jGMMX2PJYxuNiU3lcVbKmzKVmNMn2MJo5tNHT6AusYWu+vbGNPnWMLoZpNzUwGYb5fXGmP6mKAmDBF5VER2i8iKDpaLiNwnIhtEZJmITPJbdoWIrHcfVwQzzu6UGhfJ6MwEFmyyjm9jTN8SUMIQke8EUtaOWcCZB1h+FpDnPmYC/+fuOxW4HZgCTAZuF5GUQGINBceNTGPBpnLK9zV4HYoxxnSbQM8wfh5g2Veo6lzgQD+1zwWeUMd8IFlEBgFnAO+qarmqVgDvcuDEE1IuPnooDU0tPFew1etQjDGm24QfaKGInAV8AxgiIvf5LUoEmrrh+EMA/2/VYreso/L2YpyJc3ZCdnZ2N4R06EYPTGBybipPLtjMNcfnEu6zriJjTO/X2TfZdqAAqAMW+T1m45wFHCppp0wPUP71QtUHVTVfVfPT09O7IaTucfVxuWwtr+WNFTu9DsUYY7rFAc8wVHUpsFREnlLVRgC3L2Go21R0qIqBoX7vs3CSVDEwrU35nG44Xo85fVwmIzPiuX/ORr41YbDX4RhjzCELtK3kXRFJdDujlwKPicifu+H4s4HvuVdLTQUqVXUH8DZwuoikuAnqdLes1wgLE2ZMzmbVjiq2ltd4HY4xxhyyQBNGkqpWAecDj6nqUcCpnW0kIk8DnwGjRaRYRK4RketF5Hp3lTeAQmAD8BDwfQBVLQfuBBa6jzvcsl7lpFFpAPz8xeVc+djnqLbbqmaMMb3CAZuk/Ndzr166CLgt0J2r6oxOlitwYwfLHgUeDfRYoWhEejyDk6L5ZEMpANv21JKVEutxVMYYc3ACPcO4A6dJaKOqLhSR4cD64IXVN4gIJ43O2P9+WXGlh9EYY8yhCShhqOpzqjpeVW9w3xeq6gXBDa1v+K8zRvP89ccQ4ROW2vhSxpheLNA7vbNE5CV3mI9dIvKCiGQFO7i+IDUukvycVMYOSmTZVjvDMMb0XoE2ST2Gc0XTYJwb6F51y0yAxmclsbR4D0Wl+7wOxRhjDkqgCSNdVR9T1Sb3MQsInbvkeoErj80hKjyMSx+aT4WNMWWM6YUCTRilInK5iPjcx+WAjd/dBSMzEnji6imUVNdz28vLvQ7HGGO6LNCEcTXOJbU7gR3AhcBVwQqqrzoiK4mbTs7jjeU72bB7r9fhGGNMlwSaMO4ErlDVdFXNwEkgvw5aVH3YjMlDCROYvWS716EYY0yXBJowxvuPHeXedX1kcELq2zISo5k6fACzl263O7+NMb1KoAkjzH8CI3dMqUDvEjdtXHhUFkVlNfzPq6u45dkl1DU2ex2SMcZ0KtAv/T8B80TkeZxhxi8Cfhu0qPq4cycO4f6PNjJrXhEAp47N5JvjB3kblDHGdCLQO72fAC4AdgElwPmq+s9gBtaX+cKE350/nnMmDCYzMYoXFhd7HZIxxnRK+lI7en5+vhYUFHgdRpfc9eYa7v9oI+kJUbz1wxMYEB/ldUjGmH5ERBapan4g69rcoR677sTh3HzKSEr21tvsfMaYkGYJw2MpcZHcctoo8jLieXWpXWprjAldljBCgIhwzoTBLCwqZ9ueWq/DMcaYdlnCCBHnTxoCwNMLtngciTHGtM8SRojISoll+pgM/rVgM797YzV7ahp4duEWmlv6zkUJxpjeLagJQ0TOFJG1IrJBRG5tZ/lfRGSJ+1gnInv8ljX7LZsdzDhDxfUnjSDcF8YDcws5/x/z+NkLy/lwzW6vwzLGGCCICUNEfMDfgbOAccAMERnnv46q3qKqE1V1IvBX4EW/xbWty1T1W8GKM5Tk56Sy8LZTmZybSqE7b8bc9SUeR2WMMY5gnmFMBja407k2AM8A5x5g/RnA00GMp9f42ZmjyU6NZeygROaus4RhjAkNwUwYQ4Ctfu+L3bKvEZFhQC7wgV9xtIgUiMh8Efl2RwcRkZnuegUlJX3jy/WoYanM/enJXJzvjDl19ayFNlOfMcZzwUwY0k5ZRz24lwDPq6r/KHzZ7t2HlwL3iMiI9jZU1QdVNV9V89PT+9YkgGdPGMw3jxjEos0VzHhovs2hYYzxVDATRjEw1O99FtDRnWmX0KY5SlW3u8+FwBz64XDqafFR/P2ySTwzcyqNzcp5/5hnTVTGGM8EM2EsBPJEJFdEInGSwteudhKR0UAK8JlfWYqIRLmv04DjgFVBjDWkjR2UyCs3HceQ5BiumrWQeRtKvQ7JGNMPBS1hqGoTcBPwNrAa+LeqrhSRO0TE/6qnGcAz+tVREMcCBSKyFPgQuEtV+23CABiSHMPzNxzL0JQYfvHyCptDwxjT42y02l7m4/UlfPeRzxmdmcBVx+Vw4VFZhPvs/ktjzMGx0Wr7sBPy0nnsyqOpb2rm1heX88DcQq9DMsb0E5YweqGTx2Tw4U+mMW10Oo98somahiavQzLG9AOWMHopEeEHp4ykfF8DF/7fZ1z0wGcs3lLhdVjGmD7MEkYvdtSwVP4640hqG5tZXlzJn95Z63VIxpg+zBJGL3fOhMF8+JNp3Dw9j083lLFiW6XXIRlj+ihLGH3EpZOzSYmN4KfPL2PD7r3UNzXz53fWsnan87ovXQ1njPFGuNcBmO6RFBvBny6awNWzCjj1z3NJjYukfF8DnxeVU1iyjyuPy+H700Z6HaYxphezM4w+5JQxmbz2g+O549zDiInwkZcRz/zCcnbvreftFTu9Ds8Y08vZGUYfc/iQJA4fksT3jslhw+5qTv3zR4QJLNtWyY7KWjISovGFtTcupDHGHJidYfRhIzPi+f0FR/CHCyegCsf87gPufK1fj7BijDkEljD6uIuPzubbEwczJDkGgKcWbGFnZZ3HURljeiMbS6qfqGtspmRvPdP+OAeAH07PIzctjuzUWCYMTQagur4JnwgxkT4PIzXG9KSujCVlfRj9RHSEj6Gpscy66mge/ngTf3lvHaqQmRjFBz+eRrhP+PbfPyVnQCwPX3G01+EaY0KQJYx+5oS8dMYPSeb0ez4iOSaStbv28v1/LSY1LpINu6vZVLqPin0NpMRFeh2qMSbEWMLoh5JiI3jvRycRGxnO/R9t5IGPNlJV18SU3FQWbCrn3VW7uOjooZ3vyBjTr1gfhqGxuYXG5hZiInycdPccMhOj+Pd1xyBil98a09fZfBimSyJ8YcRGhiMi/McJuSwsquCdVbsAaGlRPllfSkFRucdRGmO8Zk1S5isumZzNrHlFXP/kIo7OSaVkbz2bSvcRE+Hj7f88kewBsV6HaIzxSFDPMETkTBFZKyIbROTWdpZfKSIlIrLEfVzrt+wKEVnvPq4IZpzmSxG+MJ6eOZUfnJJHXWMz6fFR/Obbh+MLEy68fx73vb/e6xCNMR4JWh+GiPiAdcBpQDGwEJihqqv81rkSyFfVm9psmwoUAPmAAouAo1T1gDMEWR9G8MxdV8I9761j8ZY9vHvLieRlJngdkjGmG4RKH8ZkYIOqFqpqA/AMcG6A254BvKuq5W6SeBc4M0hxmgCcOCqdh684mqjwMO55bz31Tc1eh2SM6WHBTBhDgK1+74vdsrYuEJFlIvK8iLReyxnotojITBEpEJGCkpKS7ojbdCA1LpKrj8/l9eU7+OZ9n/Deql28tmy712EZY3pIMBNGe9dktm3/ehXIUdXxwHvA413Y1ilUfVBV81U1Pz09/aCDNYH56RmjeeSKfIorarj2iQJueuoL/jl/s9dhGWN6QDCvkioG/O/+ygK+8nNUVcv83j4E/N5v22lttp3T7RGaLhMRpo/N5PGrJrO0eA+fbyrnly+vYHdVHedMGExDUwuHD0nyOkxjTBAEs9M7HKfTezqwDafT+1JVXem3ziBV3eG+Pg/4mapOdTu9FwGT3FUX43R6H/BmAOv07nn1Tc38/MXlvLh42/6yE/LSmJSdws3T82zuDWNCXEgMPqiqTSJyE/A24AMeVdWVInIHUKCqs4GbReRbQBNQDlzpblsuInfiJBmAOzpLFsYbUeE+/nzRRC6fOow1O/ays7KWl5Zs4+P1pWQmRnPplGyvQzTGdBMbGsR0O1Xl4gfns2ZHFY9eeTT5Oaleh2SM6UBInGGY/ktEuPvC8Vzx6Odc9MBnTByaTGVtIzdPz+OLLXv4yRmjiY+yf3rG9Db2v9YExbABcbxy4/Hc98F6PttYRkVNIz98ZgkAJdX13HvxRMJ9NpSZMb2JJQwTNEmxEfzy7HEArN5RxVMLthAb5eOBjwopKCpnYFIMmQnO0CMZidEeR2uM6Yz9xDM9YuygRO789uHceuYYHvpePvnDUkmOieCjdSX8+LmlLN26B1WlsqaRW55dwo7KWq9DNsa0YWcYpkeJCKeNy+S0cZkAPD6viNtnr+Tj9aXcfs44GptbeOmLbWSnxnLLaaM8jtYY48/OMIynrjg2hzd/eAInj07nd2+u4ZFPNgHw5oodHkdmjGnLEobx3NhBidz9nQmMHZTIrqp6jhqWwrpd1fz+rTXWNGVMCLH7MEzIaG5Rlm+rZHByNJc+tIDCkmpiI8P5rzNGc1H+UGIifV6HaEyf05X7MCxhmJC1uWwfv3h5BR+vLyU8TBgQH8mErGQumzqME/PSbM5xY7qBJQzTZ6gqn2woZUFhOdsra/l0Qym7qurJTo3l5ul5vLComPMnDeE7+UM735kx5mvsTm/TZ4gIJ+Slc0KeM3R9Q1MLLy/ZxqOfbOInzy0FYNHmCgbER3Ly6AxqG5uJ9IWhQJiIDX5oTDeyMwzTK1XWNvI/s1dyfF4a97y3ni3lNYzMiGdLWQ0Dk6Kp2NfAeZOGcMe5h3sdqjEhzZqkTL9S19jMK0u28czCrQxLjWVjyT5Kq+spra7n45+ewsCkr95F3tjcgoANTWIMljC8DsOEgK3lNUz74xzGDUrk2JED2Fxaw7C0WK47cQRXPfY54b4wnp051ZKG6fcsYRgD/HvhVh78uJAtZTWkJ0SxvbKWSF8Y9U0tANx8ykh+dPpoj6M0xlvW6W0McNHRQ7no6C+vnlpWvIffvr6akRnx1DW2cN8HG9hVVc8FR2UxKTuZO15bRU1DM3/8zgQPozYmdFnCMP3G+Kxknr3uGMDpxwB4eck2Xlm6jcm5A5i7rgSAyTmpVNU1MiIjnpNHZ3gWrzGhxpqkTL+2s7KO0//yEVV1TfzszDE8MHcje2oaAYjwCe//aBrZA2I9jtKY4AmZJikRORO4F2dO74dV9a42y38EXIszp3cJcLWqbnaXNQPL3VW3qOq3ghmr6Z8GJkXzxDVTqKpt5MRR6WQkRFGwuZzLpgzjwvvn8cNnv+CEvHSm5qZy7Mg0r8M1xlNBO8MQER+wDjgNKAYWAjNUdZXfOicDC1S1RkRuAKap6sXusmpVje/KMe0Mw3Snxz7dxJ/fWce+hiZaFC7OH8rApGiWb6skOzWWS6dkMyozAYCWFmVHVR1DkmM8jtqYrgmVM4zJwAZVLXSDegY4F9ifMFT1Q7/15wOXBzEeY7rkquNyueq4XOoam/nDW2t54rMimlqUUZnxfLqhlFnzipg+JoN7ZxzJXW+u5qkFW5h90/EcPiTJ69CNCYpgnmFcCJypqte6778LTFHVmzpY/2/ATlX9jfu+CViC01x1l6q+3MF2M4GZANnZ2Udt3ry52+tiDEBNQxPV9U1kJDh3kj85fzP3vL+ewcnRbC13hmEfOyiR+CgfN0wbwSljMlmzs4qfv7icv844ktjIcFLjIj2uhTFfFSoWKhYKAAATYklEQVRnGO0N4tNudhKRy4F84CS/4mxV3S4iw4EPRGS5qm782g5VHwQeBKdJ6tDDNqZ9sZHhxEY6/2VS4iL5wfQ8hqTE8I85G/mPE3IJE+GBuYXER4Vz9awC/vsbY5iztoQvtuxh5hOLWLWjirPHD+IPF47fvx9jepNg/qstBvyHEM0CtrddSUROBW4DTlLV+tZyVd3uPheKyBzgSOBrCcMYL50/KYvzJ2UBUN/UzHEj05icm8otzy7hf99YA0B6QhSrdlQxJDmG15fvIDUukutOGsE9767jplNGUt/Uwsj0eMJsoEQT4oLZJBWO0+k9HdiG0+l9qaqu9FvnSOB5nKar9X7lKUCNqtaLSBrwGXCuf4d5e6zT24SKpuYWPlizm5LqevKHpfLLV1bwm28fztOfb+GxT4tIjA6nqq6JQUnR7Kis4/Kp2VTsa+SaE3KZlJ3idfimHwmZoUFE5BvAPTiX1T6qqr8VkTuAAlWdLSLvAUcArRM4b1HVb4nIscADQAvONLL3qOojnR3PEoYJdbUNzfz1g/UUle0jMzGaxz4tIibCR21jMwBDU2M4Y9xAUuIiyU6N5aUvtnHp5Gymj83gT++s44S8NKYMH+BxLUxfEjIJo6dZwjC9SUuL8t7qXeRlJvCz55cxOTeVv8/ZQERYGA3unegAidHh3Dw9j9+8vppRmfFccWwOYwYmcNSwVA+jN32FJQxjeqnNZfvISIimoamFDSV7iY7wcfED86mubyIu0se+BudMJMInTByaTEZiNN+bOozZS7cTG+njx6ePJjrCmfv8gzW7iPCF7Z98ypj2WMIwpg8prqjh3wu3cuq4TO5+ey3jBidSUlVP8Z5aCt25P1qNzkzg9xeOp6ConN+8vpqU2Ag++/n0/UnEmLYsYRjTT+ypaeDGpxYzZmAix+el8V/PLaW0ugGAI4YksXxbJaeOzSArJZYjhiQxODmG/JwUfCKIgCp2dVY/ZwnDmH6qsraR2Uu3kxobyVmHD+Tsv37C6p1VX5kHBCAvI54R6fHM21jKWYcP4uQxGZx5+MD9y59fVMwTnxXxr2unkBAd4UFNTE+xhGGMAaBkbz11jc2kxkWye289X2ypYO2uvcz6tIj6phYm56SyZmcVVXVN3H/5JEZmJFBZ28BVjy2kqq6JH502ipun53V6nIamFiLDbfbCYPt0QykVNQ2cPX5wt+0zVO70NsZ4LD0hav/r3KhwctPiADhpVDqFJfu4bEo29U0tfOtvn3D9k4v3r+sLEyZkJfHARxupqGmgqHQf38kf6lzVlZHAVcflEB3ho66xmTlrS7j56S946cZjOWywjaMVTPd/tJHiitpuTRhdYQnDmH7o2BFpHDvCGa49OsLHk9dM4d3Vu4iPcoY/yU2LJTrCxw1PLuaxT4uIDA/jw7UlxEeF8+Libbz8xTYOH5LEy0u2ERXuXAb8/KLiryWM8n0N/O8bq7nx5JH7k5U5eGXVDZT5XeTQ0yxhGGPISIzmsinDvlb+0vePpbK2kZ1Vdcxesp3vTxvJF1sr+NUrK3lhcTHTRqezpbyG+KhwXl26g9PGZlKwuYKq2kZOGZvBIx9v4v01u6lpaOIflx0FQGVNI5c+PJ9bTh3FqeMye7qqvVrZvnqq6ppobG4hwtfzTYDWh2GM6bLmFqWipoG0eKfJ6+2VO7nun4sAEIHwMKGx2fluGZ2ZwLrdezlm+AAm56ZSWl3Pk/O3cNjgRF77wfGIOFdprd5RRVZKjHWyd0BVybvtTZpalM9vm05GQnS37Nf6MIwxQeULk/3JAuD0cZk8M3MqdY3NTBqWQpgIH67ZTW5aHIOTY7hq1kIqaxu59/31qEJafBQrt1cx9ldvkRwTybjBiXywZjejMxP42VmjmZSdwmcby/CFCSePyfDk13SoqaptoqnFScLl+xq6LWF0hSUMY8whExGmthnj6pwJX3bMvnLjcQBsLa/h3VW7OG1cJj95bimDk2NobG5hfmEZZxyWydx1pVw9q4AI35dnKIcNTuS2b4xl/NBkosPDKK1uICkmgphIH6rKF1v3EBvpY8zARHZU1rKvvomRGQk9V/keUrrvy76Lcvdem55mCcMY02OGpsZy9fG5ADx73TFfW15aXc+6XXt5duFWJmQlk5YQxS9fXsGlDy9AxJlkp0UhITqcnAFxFJXtY29dEyJwxriBzNtYSm1jM+dOHMLYQYlcfVzO/iav3q7ML0mU11jCMMb0c2nxUaTFR+2/ggucS4AXb65gWXElzS0tpCdGs3hzBaXV9ZyXPYQJWcms2lHFq0u3k5seT3p8FG8u38Hzi4p5cXExmYnRzJicTWykj8zEaOqbmtm+p45TxmTg87vLXVU7TS47K+sYmNTzTUHAV66OKt9nCcMYY74mKSaCk8dkcPKYjP1l35361Su6LgB+efa4/e9Vlb+8t54P1+xmydY9fLBm99f2m5EQRWZiNCePyWDltkoWFpVzwqh05m8s239/ys6qOn5wykhGZiTwwEcb+d2ba7jz24dz6tgM/vDWWn44PY+cTi4XVlXufX89p47NPKT53kv9kkSZNUkZY0z3EBF+dNoofnTaKKrqGlmzYy+qypbyGuqaWoiP8vHBmhK2lO3jvvfXkxwbQU5aHK8v28G4QYnc98EGInxCpC+Mt1fu5MihKczfVEZcpI87X13F4/OK2LC7muKKGm4/5zBGZsTvv5HxxcXbOGVMxv4zkTlrS7jnvfV8uqGU564/ttPY1+3aS0yEj6GpsV8pbz3DSIgKp8KapIwxpvslRkcwOdeZO8R/8qnzjnSm1q1rbCYqPAxVpw8lPSGKippGEqLDKatu4N7311FQVMG1x+dy5XG53P7KCj5cW8LZ4wfx2rIdnP3XT4gKD2Pi0GSKK2rZtqeWzMQoctPiiI7wsbGkmjCBhUUVPFewlZ2VdXxWWMak7BRumDaCWfOKKKtu4JwJgxiZEc/FD3xGalwk79xy0leazMqqG0iJjSAlNpIyj5qk7D4MY4zpovqmZiJ9YSzeUsGuqnoKiipYtLmclLhITh83kKc+30yEL4zG5hbKqhu45dRR/O3DDWwpr0HEGfxx3a5qosKdQSEjw8NoaGohLyOe9burATh/0hBUoalFaVFlQWEZSTERJMdGEukL4+mZU7ulLjb4oDHGhJi6xmY+KywjZ0AcuWlxFBSV8/DHm5icm8rFRw/l/+Zs5MkFmzlpVDpFZTUs3bqHIckxhPuEMBGyUmI4d+IQ3l21k/dX7yY7NRYFWlRJjo3cf+lyV4VMwhCRM4F7ceb0flhV72qzPAp4AjgKKAMuVtUid9nPgWuAZuBmVX27s+NZwjDG9GYtLYoINDYrzS1KTOTXJ75au9O57HjX3jrCRAgT58KAO849/KCOGRJ3eouID/g7cBpQDCwUkdmquspvtWuAClUdKSKXAL8HLhaRccAlwGHAYOA9ERmlqs3BitcYY7zWOplVZHjHl/eOHpjAr84Z1+HyYArm/faTgQ2qWqiqDcAzwLlt1jkXeNx9/TwwXZwLoc8FnlHVelXdBGxw92eMMcYjwUwYQ4Ctfu+L3bJ211HVJqASGBDgtsYYY3pQMBNGe+dUbTtMOlonkG2dHYjMFJECESkoKSnpYojGGGMCFcyEUQwM9XufBWzvaB0RCQeSgPIAtwVAVR9U1XxVzU9PT++m0I0xxrQVzISxEMgTkVwRicTpxJ7dZp3ZwBXu6wuBD9S5bGs2cImIRIlILpAHfB7EWI0xxnQiaFdJqWqTiNwEvI1zWe2jqrpSRO4AClR1NvAI8E8R2YBzZnGJu+1KEfk3sApoAm60K6SMMcZbduOeMcb0Y125D8OmsTLGGBOQPnWGISIlwOaD3DwNKO3GcLxkdQk9faUeYHUJVQdbl2GqGtAVQ30qYRwKESkI9LQs1FldQk9fqQdYXUJVT9TFmqSMMcYExBKGMcaYgFjC+NKDXgfQjawuoaev1AOsLqEq6HWxPgxjjDEBsTMMY4wxAbGEYYwxJiD9PmGIyJkislZENojIrV7H01UiUiQiy0VkiYgUuGWpIvKuiKx3n1O8jrM9IvKoiOwWkRV+Ze3GLo773M9pmYhM8i7yr+ugLr8WkW3uZ7NERL7ht+znbl3WisgZ3kTdPhEZKiIfishqEVkpIj90y3vdZ3OAuvS6z0ZEokXkcxFZ6tblf9zyXBFZ4H4uz7pj9+GOxfesW5cFIpJzyEGoar994IxxtREYDkQCS4FxXsfVxToUAWltyv4A3Oq+vhX4vddxdhD7icAkYEVnsQPfAN7EGfp+KrDA6/gDqMuvgZ+0s+44999aFJDr/hv0eV0Hv/gGAZPc1wnAOjfmXvfZHKAuve6zcf++8e7rCGCB+/f+N3CJW34/cIP7+vvA/e7rS4BnDzWG/n6GEcisgL2R/0yGjwPf9jCWDqnqXJxBJ/11FPu5wBPqmA8ki8ignom0cx3UpSMhPaOkqu5Q1cXu673AapwJzHrdZ3OAunQkZD8b9+9b7b6NcB8KnIIzYyl8/XNpb0bTg9bfE0ZfmNlPgXdEZJGIzHTLMlV1Bzj/YYAMz6Lruo5i762f1U1uM82jfk2DvaYubjPGkTi/Znv1Z9OmLtALPxsR8YnIEmA38C7OGdAedWYsha/G29GMpgetvyeMgGf2C2HHqeok4CzgRhE50euAgqQ3flb/B4wAJgI7gD+55b2iLiISD7wA/KeqVh1o1XbKQqo+7dSlV342qtqsqhNxJpWbDIxtbzX3udvr0t8TRsAz+4UqVd3uPu8GXsL5R7SrtUnAfd7tXYRd1lHsve6zUtVd7n/wFuAhvmzaCPm6iEgEzhfsv1T1Rbe4V3427dWlN382AKq6B5iD04eRLM6MpfDVeDua0fSg9feEEcisgCFLROJEJKH1NXA6sIKvzmR4BfCKNxEelI5inw18z70iZypQ2do8EqratOOfh/PZQIjPKOm2cz8CrFbVP/st6nWfTUd16Y2fjYiki0iy+zoGOBWnT+ZDnBlL4eufS3szmh48r3v+vX7gXOGxDqct8Dav4+li7MNxruhYCqxsjR+nnfJ9YL37nOp1rB3E/zROc0Ajzq+hazqKHef0+u/u57QcyPc6/gDq8k831mXuf95Bfuvf5tZlLXCW1/G3qcvxOE0Xy4Al7uMbvfGzOUBdet1nA4wHvnBjXgH8yi0fjpPUNgDPAVFuebT7foO7fPihxmBDgxhjjAlIf2+SMsYYEyBLGMYYYwJiCcMYY0xALGEYY4wJiCUMY4wxAbGEYUKeiMxzn3NE5NJu3vd/t3esYBGRb4vIr4K07//ufK0u7/MIEZnV3fs1vZNdVmt6DRGZhjPC6Nld2Manqs0HWF6tqvHdEV+A8cwDvqWqpYe4n6/VK1h1EZH3gKtVdUt379v0LnaGYUKeiLSO0HkXcII7f8Et7kBsd4vIQncQuevc9ae5cyA8hXNzFiLysjtA48rWQRpF5C4gxt3fv/yP5d61fLeIrBBnvpGL/fY9R0SeF5E1IvKv1hFAReQuEVnlxvLHduoxCqhvTRYiMktE7heRj0VknYic7ZYHXC+/fbdXl8vFmT9hiYg8ICK+1jqKyG/FmVdhvohkuuXfceu7VETm+u3+VZxREEx/5/Xdi/awR2cPoNp9nga85lc+E/iF+zoKKMCZw2AasA/I9Vu39a7kGJy7ZAf477udY12AMxqoD8gEtuDMrTANZ9TPLJwfXJ/h3E2cinNncOtZe3I79bgK+JPf+1nAW+5+8nDuEI/uSr3ai919PRbniz7Cff8P4HvuawXOcV//we9Yy4EhbeMHjgNe9frfgT28f7QOWGVMb3Q6MF5EWsfRScL54m0APldnPoNWN4vIee7roe56ZQfY9/HA0+o0++wSkY+Ao4Eqd9/FAOIMNZ0DzAfqgIdF5HXgtXb2OQgoaVP2b3UGwFsvIoXAmC7WqyPTgaOAhe4JUAxfDhbY4BffIuA09/WnwCwR+Tfw4pe7YjcwOIBjmj7OEobpzQT4gaq+/ZVCp69jX5v3pwLHqGqNiMzB+SXf2b47Uu/3uhkIV9UmEZmM80V9CXATzsQ2/mpxvvz9te1EVAKsVycEeFxVf97OskZVbT1uM+73gKpeLyJTgG8CS0RkoqqW4fytagM8runDrA/D9CZ7cabZbPU2cIM4w1cjIqPcUXvbSgIq3GQxBmdI6FaNrdu3MRe42O1PSMeZgrXDUUvFmW8hSVXfAP4TZ56FtlYDI9uUfUdEwkRkBM4gcmu7UK+2/OvyPnChiGS4+0gVkWEH2lhERqjqAlX9FVDKl8N8j+LL0VxNP2ZnGKY3WQY0ichSnPb/e3Gagxa7Hc8ltD8d7VvA9SKyDOcLeb7fsgeBZSKyWFUv8yt/CTgGZyRgBX6qqjvdhNOeBOAVEYnG+XV/SzvrzAX+JCLi9wt/LfARTj/J9apaJyIPB1ivtr5SFxH5Bc5sjGE4o+jeCGw+wPZ3i0ieG//7bt0BTgZeD+D4po+zy2qN6UEici9OB/J77v0Nr6nq851s5hkRicJJaMfrl9OAmn7KmqSM6Vn/C8R6HUQXZAO3WrIwYGcYxhhjAmRnGMYYYwJiCcMYY0xALGEYY4wJiCUMY4wxAbGEYYwxJiD/D+pUZeEmZEN1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.9990741\n",
      "Test Accuracy: 0.71666664\n"
     ]
    }
   ],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
